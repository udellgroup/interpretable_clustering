{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Clustering Code \n",
    "\n",
    "* Code is based on this implementation of decision tree: https://machinelearningmastery.com/implement-decision-tree-algorithm-scratch-python/\n",
    "* This code builds decision tree using tree distances \n",
    "* Data Requirements:\n",
    "    - numerical \n",
    "    - the first column must be the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sort values first - binary search \n",
    "# distance matrix - rather than for every pair (all-to-all shortest pathes )\n",
    "# try hashing data structures \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import scipy.stats as sc\n",
    "#import shap\n",
    "#import lime\n",
    "import sklearn \n",
    "import warnings\n",
    "#import xgboost\n",
    "\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "import pickle \n",
    "#import interpret\n",
    "import collections\n",
    "import math\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import  RandomForestRegressor\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn import preprocessing\n",
    "#from interpret.glassbox import ExplainableBoostingClassifier\n",
    "#from interpret import show\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from interpret.glassbox import ExplainableBoostingRegressor\n",
    "#from interpret import show\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "%matplotlib inline\n",
    "import os, sys\n",
    "#import statsmodels.api as sm\n",
    "sys.path.append(os.path.abspath(\"../../../\"))\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "#import eli5\n",
    "#from eli5.sklearn import PermutationImportance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_final_dist = pd.read_csv(\"train_final_dist.csv\")\n",
    "test_final_dist = pd.read_csv(\"test_final_dist.csv\")\n",
    "full_data_train = pd.read_csv(\"full_data_train.csv\")\n",
    "full_data_test = pd.read_csv(\"full_data_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_final_dist = train_final_dist[['i1', 'i2', 'tree_dist']]\n",
    "test_final_dist = test_final_dist[[\"i1\", \"i2\", \"tree_dist\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = full_data_train[[\"Survived\", \"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Deck\"]]\n",
    "df_test = full_data_test[[\"Survived\", \"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Deck\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_train = df_train.to_numpy()\n",
    "dataset_test = df_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "small_df_train = full_data_train_no_clust.head(50)\n",
    "small_df_test = full_data_test_no_clust.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "small_dataset_train = small_df_test.to_numpy()\n",
    "small_dataset_test = small_df_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split a dataset based on an attribute and an attribute value\n",
    "def test_split(index, value, dataset, df):\n",
    "    feature = df.columns[index]\n",
    "    left, right = list(), list()\n",
    "    indleft, indright = list(), list()\n",
    "    left_df, right_df = pd.DataFrame(columns = df.columns), pd.DataFrame(columns = df.columns)\n",
    "    for i, row in df.iterrows():\n",
    "        if row[feature] < value:\n",
    "            indleft.append(i)\n",
    "            left_df = left_df.append(row) \n",
    "        else:\n",
    "            indright.append(i)\n",
    "            right_df = right_df.append(row) \n",
    "    for row in dataset:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right, indleft, indright, left_df, right_df\n",
    " \n",
    "# Calculate the distance index for a split dataset\n",
    "def distance_index(left, right, indleft, indright):\n",
    "    mean_left_dist = 0\n",
    "    mean_right_dist = 0\n",
    "    for i in range(len(indleft)):\n",
    "        for j in range(i+1, len(indleft)):\n",
    "            nodei_df = train_final_dist[train_final_dist['i1'] == indleft[i]]\n",
    "            nodei_j_df = nodei_df[nodei_df['i2'] == indleft[j]]\n",
    "            dist =  float(nodei_j_df[\"tree_dist\"])\n",
    "            mean_left_dist += dist \n",
    "    for i in range(len(indright)):\n",
    "        for j in range(i+1, len(indright)):\n",
    "            nodei_df = test_final_dist[test_final_dist['i1'] == indright[i]]\n",
    "            nodei_j_df = nodei_df[nodei_df['i2'] == indright[j]]\n",
    "            dist =  float(nodei_j_df[\"tree_dist\"])\n",
    "            mean_right_dist += dist\n",
    "    mean_left_dist = 0\n",
    "    mean_right_dist = 0\n",
    "    if len(indleft) > 0:\n",
    "        mean_left_dist = mean_left_dist / (len(indleft) + 1)\n",
    "    if len(indright) > 0:\n",
    "        mean_right_dist = mean_right_dist / (len(indright) +1)\n",
    "    out = 0\n",
    "    if \n",
    "    return mean_left_dist * len(left) / (len(left) + len(right)) + mean_right_dist * len(right) / (len(left) + len(right))\n",
    "\n",
    "# Select the best split point for a dataset\n",
    "def get_split(dataset, df):\n",
    "    class_values = list(set(row[0] for row in dataset))\n",
    "    b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "    for index in range(1, len(dataset[0])):\n",
    "        for row in dataset:\n",
    "            left, right, indleft, indright, left_df, right_df = test_split(index, row[index], dataset, df)\n",
    "            groups = left, right, left_df, right_df\n",
    "            dist = distance_index(left, right, indleft, indright)\n",
    "            if dist < b_score:\n",
    "                b_index, b_value, b_score, b_groups = index, row[index], dist, groups\n",
    "    return {'index':b_index, 'value':b_value, 'groups':b_groups}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a leaf node value\n",
    "def to_terminal(group):\n",
    "    outcomes = [row[0] for row in group]\n",
    "    return max(set(outcomes), key=outcomes.count)\n",
    " \n",
    "# Create child splits for a node or make leaf\n",
    "def split(node, max_depth, min_size, depth):\n",
    "    left, right, left_df, right_df = node['groups']\n",
    "    del(node['groups'])\n",
    "    # check for a no split\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = to_terminal(left + right)\n",
    "        return\n",
    "    # check for max depth\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    # process left child\n",
    "    if len(left) <= min_size:\n",
    "        #print('here')\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left, left_df)\n",
    "        split(node['left'], max_depth, min_size, depth+1)\n",
    "    # process right child\n",
    "    if len(right) <= min_size:\n",
    "        #print('here')\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        #print('here')\n",
    "        node['right'] = get_split(right, right_df)\n",
    "        split(node['right'], max_depth, min_size, depth+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build a decision tree\n",
    "def build_tree(train, df, max_depth, min_size):\n",
    "    root = get_split(train, df)\n",
    "    split(root, max_depth, min_size, 1)\n",
    "    return root\n",
    " \n",
    "# Print a decision tree\n",
    "def print_tree(node, df, depth=0):\n",
    "    if isinstance(node, dict):\n",
    "        print('%s[%s < %.3f]' % ((depth*' ', (df.columns[node['index']]), node['value'])))\n",
    "        print_tree(node['left'], df, depth+1)\n",
    "        print_tree(node['right'], df, depth+1)\n",
    "    else:\n",
    "        print('%s[%s]' % ((depth*' ', node)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(node, row):\n",
    "    if row[node['index']] < node['value']:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = small_df_train[[\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Deck\"]]\n",
    "y_train = small_df_train['Survived']\n",
    "X_test = small_df_test[[\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Deck\"]]\n",
    "y_test = small_df_test['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "clf = RandomForestClassifier(max_depth=5, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35  1]\n",
      " [ 6  8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_small = build_tree(small_dataset_train, small_df_train, 5, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fare < 9.000]\n",
      " [Age < 27.000]\n",
      "  [0]\n",
      "  [0]\n",
      " [Age < 29.000]\n",
      "  [0]\n",
      "  [0]\n"
     ]
    }
   ],
   "source": [
    "print_tree(tree_small, small_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_dt = []\n",
    "for row in small_dataset_test:\n",
    "    y_pred_dt.append(predict(tree_small, row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36  0]\n",
      " [14  0]]\n"
     ]
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(y_test, y_pred_dt)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8635230352303523, 0.86, 0.8493280632411068, None)\n"
     ]
    }
   ],
   "source": [
    "# weighted precision, recall, f-score, support \n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "print(precision_recall_fscore_support(y_test, y_pred, average ='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5184, 0.72, 0.6027906976744185, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aparnacalambur/anaconda/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(precision_recall_fscore_support(y_test, y_pred_dt, average ='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create distances based on test distances \n",
    "\n",
    "# applying the decision rule to test set (supervised)\n",
    "# applying to train (semi-supervised notion of clustering)\n",
    "# - we are using distance generated by test set and clustering based on that \n",
    "# - we use distance metric (metric = forest) to get distance matrix for test set - training set provides metric\n",
    "# - you can also build distance from both trained and test ?????\n",
    "# - when test bigger than training - semi-supervised (more unlabeled than labeled)\n",
    "# we are doing train/test split - but how we predict we use majority vote of training within cluster\n",
    "# build from: training + test set OR just train\n",
    "\n",
    "# how to evaluate clusters in the end: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_final_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.782178217821784"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodei_df = train_final_dist[train_final_dist['i1'] == 283]\n",
    "nodei_j_df = nodei_df[nodei_df['i2'] == 284]\n",
    "float(nodei_j_df[\"tree_dist\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i1</th>\n",
       "      <th>i2</th>\n",
       "      <th>tree_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.752475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.336634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.970297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.396040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>9.287129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193748</th>\n",
       "      <td>619</td>\n",
       "      <td>621</td>\n",
       "      <td>13.227723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193749</th>\n",
       "      <td>619</td>\n",
       "      <td>622</td>\n",
       "      <td>10.168317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193750</th>\n",
       "      <td>620</td>\n",
       "      <td>621</td>\n",
       "      <td>11.425743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193751</th>\n",
       "      <td>620</td>\n",
       "      <td>622</td>\n",
       "      <td>12.980198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193752</th>\n",
       "      <td>621</td>\n",
       "      <td>622</td>\n",
       "      <td>10.584158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193753 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         i1   i2  tree_dist\n",
       "0         0    1  10.752475\n",
       "1         0    2  10.336634\n",
       "2         0    3  10.970297\n",
       "3         0    4   5.396040\n",
       "4         0    5   9.287129\n",
       "...     ...  ...        ...\n",
       "193748  619  621  13.227723\n",
       "193749  619  622  10.168317\n",
       "193750  620  621  11.425743\n",
       "193751  620  622  12.980198\n",
       "193752  621  622  10.584158\n",
       "\n",
       "[193753 rows x 3 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_node_depths(tree1):\n",
    "    def get_node_depths_(current_node, current_depth, l, r, depths):\n",
    "        depths += [current_depth]\n",
    "        if l[current_node] != -1 and r[current_node] != -1:\n",
    "            get_node_depths_(l[current_node], current_depth + 1, l, r, depths)\n",
    "            get_node_depths_(r[current_node], current_depth + 1, l, r, depths)\n",
    "\n",
    "    depths = []\n",
    "    get_node_depths_(0, 0, tree1.tree_.children_left, tree1.tree_.children_right, depths) \n",
    "    return np.array(depths)\n",
    "\n",
    "def get_shared_nodes(i1,i2,node_indicator,n_nodes):\n",
    "    sample_ids = [i1, i2]\n",
    "    common_nodes = (node_indicator.toarray()[sample_ids].sum(axis=0) ==\n",
    "                    len(sample_ids))\n",
    "    \n",
    "    common_node_id = np.arange(n_nodes)[common_nodes]\n",
    "    \n",
    "    return common_node_id\n",
    "\n",
    "# Tree distance between nodes n1, n2 = depth(n1) + depth(n2) - 2 depth(LCA)\n",
    "def distance_between_samples(indexes,depths,leaves,node_indicator,n_nodes):\n",
    "    i1 = indexes[0]\n",
    "    i2 = indexes[1]\n",
    "    leaf_node1 = leaves[i1]\n",
    "    leaf_node2 = leaves[i2]\n",
    "    depth_node1 = depths[leaf_node1]\n",
    "    depth_node2 = depths[leaf_node2]\n",
    "    ancestors = get_shared_nodes(i1,i2,node_indicator,n_nodes)\n",
    "    depth_LCA = max(depths[ancestors])\n",
    "    \n",
    "    dist = depth_node1 + depth_node2 - 2*depth_LCA\n",
    "    if dist < 0:\n",
    "        #print(len(depths))\n",
    "        depths[ancestors]\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bootstraps data and builds a tree, then calculates pairwise distances on the data instances relative to the tree\n",
    "# Tree distance is calculated via lowest common ancestor\n",
    "def build_tree(xTrain,yTrain,xTest):\n",
    "    train = xTrain.copy()\n",
    "    train['y'] = yTrain\n",
    "    train1 = train.sample(n = len(train), replace = True) \n",
    "    yTrain1 = train1['y']\n",
    "    xTrain1 = train1.drop('y',axis = 1)\n",
    "    gc.collect()\n",
    "    estimator = DecisionTreeClassifier().fit(xTrain1,yTrain1)\n",
    "    n_nodes = estimator.tree_.node_count\n",
    "    depths = get_node_depths(estimator)\n",
    "    leaves_train = estimator.apply(xTrain)\n",
    "    leaves_test = estimator.apply(xTest)\n",
    "    node_indicator_test = estimator.decision_path(xTest)\n",
    "    node_indicator_train = estimator.decision_path(xTrain)\n",
    "    train_comb = list(itertools.combinations(range(0,len(xTrain)), 2))\n",
    "    test_comb = list(itertools.combinations(range(0,len(xTest)), 2))\n",
    "    print(type(leaves_test))\n",
    "    ### Train Distances\n",
    "    train_distances = []\n",
    "    for indexes in train_comb:\n",
    "        dist = distance_between_samples(indexes,depths,leaves_train,node_indicator_train,n_nodes)\n",
    "        train_distances.append([indexes[0],indexes[1],dist])\n",
    "\n",
    "    ### Test Distances\n",
    "    test_distances = []\n",
    "    for indexes in test_comb:\n",
    "        dist = distance_between_samples(indexes,depths,leaves_train,node_indicator_test,n_nodes)\n",
    "        test_distances.append([indexes[0],indexes[1],dist])\n",
    "\n",
    "    train_dist_df = pd.DataFrame(train_distances, columns = ['i1','i2','tree_dist'])\n",
    "    test_dist_df = pd.DataFrame(test_distances, columns = ['i1','i2','tree_dist'])\n",
    "    return(estimator,train_dist_df,test_dist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "estimator,train_dist_df,test_dist_df = build_tree(X_train,y_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_node_count(node, df, depth=0):\n",
    "    num_nodes = 0\n",
    "    if isinstance(node, dict):\n",
    "        num_nodes += 1 + get_node_count(node['left'], df, depth+1)\n",
    "        num_nodes += 1 + get_node_count(node['right'], df, depth+1)\n",
    "    else:\n",
    "        num_nodes += 1\n",
    "    return num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 6,\n",
       " 'left': {'index': 3, 'left': 0, 'right': 0, 'value': 27},\n",
       " 'right': {'index': 3, 'left': 0, 'right': 0, 'value': 29},\n",
       " 'value': 9}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "n_nodes = estimator.tree_.node_count\n",
    "depths = get_node_depths(estimator)\n",
    "leaves_train = estimator.apply(xTrain)\n",
    "leaves_test = estimator.apply(xTest)\n",
    "node_indicator_test = estimator.decision_path(xTest)\n",
    "node_indicator_train = estimator.decision_path(xTrain)\n",
    "train_comb = list(itertools.combinations(range(0,len(X_train)), 2))\n",
    "test_comb = list(itertools.combinations(range(0,len(X_test)), 2))\n",
    "\n",
    "### Test Distances\n",
    "test_distances = []\n",
    "for indexes in test_comb:\n",
    "    dist = distance_between_samples(indexes,depths,leaves_train,node_indicator_test,n_nodes)\n",
    "    test_distances.append([indexes[0],indexes[1],dist])\n",
    "\n",
    "train_dist_df = pd.DataFrame(train_distances, columns = ['i1','i2','tree_dist'])\n",
    "test_dist_df = pd.DataFrame(test_distances, columns = ['i1','i2','tree_dist'])\n",
    "return([estimator,train_dist_df,test_dist_df])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
