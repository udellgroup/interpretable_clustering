{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import scipy.stats as sc\n",
    "#import shap\n",
    "#import lime\n",
    "import sklearn \n",
    "import warnings\n",
    "#import xgboost\n",
    "\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "import pickle \n",
    "#import interpret\n",
    "import collections\n",
    "import math\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import  RandomForestRegressor\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn import preprocessing\n",
    "#from interpret.glassbox import ExplainableBoostingClassifier\n",
    "#from interpret import show\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from interpret.glassbox import ExplainableBoostingRegressor\n",
    "#from interpret import show\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "%matplotlib inline\n",
    "import os, sys\n",
    "#import statsmodels.api as sm\n",
    "sys.path.append(os.path.abspath(\"../../../\"))\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "#import eli5\n",
    "#from eli5.sklearn import PermutationImportance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_final_dist = pd.read_csv(\"test_final_dist.csv\")\n",
    "full_data_test = pd.read_csv(\"full_data_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_test_no_clust = full_data_test[[\"Survived\", \"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Deck\"]]\n",
    "full_data_test_no_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = full_data_test[[\"Survived\", \"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Deck\"]]\n",
    "y = full_data_test[[\"clust\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dt_feature_names = list(X.columns)\n",
    "dt_target_names = [\"0\", \"1\", \"2\"]\n",
    "clf = DecisionTreeClassifier(max_depth=3).fit(X, y)\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "_ = tree.plot_tree(clf, \n",
    "                   feature_names=dt_feature_names,  \n",
    "                   class_names=dt_target_names,\n",
    "                   filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split a dataset based on an attribute and an attribute value\n",
    "def test_split(feature, value, df):\n",
    "    left, right = list(), list()\n",
    "    indleft, indright = list(), list()\n",
    "    for index, row in df.iterrows():\n",
    "        if row[feature] < value:\n",
    "            left.append(row)\n",
    "            indleft.append(index)\n",
    "        else:\n",
    "            right.append(row)\n",
    "            indright.append(index)\n",
    "    return left, right, indleft, indright\n",
    " \n",
    "# Calculate the distance index for a split dataset\n",
    "def distance_index(left, right, indleft, indright):\n",
    "    mean_left_dist = 0\n",
    "    mean_right_dist = 0\n",
    "    for i in range(len(indleft)-1):\n",
    "        nodei_df = test_final_dist[test_final_dist['i1'] == i]\n",
    "        nodei_j_df = nodei_df[nodei_df['i2'] == i+1]\n",
    "        dist = test_final_dist[\"tree_dist\"][0]\n",
    "        mean_left_dist += dist \n",
    "    for i in range(len(indright)-1):\n",
    "        nodei_df = test_final_dist[test_final_dist['i1'] == i]\n",
    "        nodei_j_df = nodei_df[nodei_df['i2'] == i+1]\n",
    "        dist = test_final_dist[\"tree_dist\"][0]\n",
    "        mean_right_dist += dist\n",
    "    if len(left) == 0 and len(right) == 0:\n",
    "        return 0\n",
    "    elif len(left) == 0:\n",
    "        mean_left_dist = 0\n",
    "        mean_right_dist = mean_right_dist / len(indright)\n",
    "        return mean_left_dist * len(left) / (len(left) + len(right)) + mean_right_dist * len(right) / (len(left) + len(right))\n",
    "    elif len(right) == 0:\n",
    "        mean_left_dist = mean_left_dist / len(indleft)\n",
    "        mean_right_dist = 0\n",
    "        return mean_left_dist * len(left) / (len(left) + len(right)) + mean_right_dist * len(right) / (len(left) + len(right))\n",
    "    else:\n",
    "        mean_left_dist = mean_left_dist / len(indleft)\n",
    "        mean_right_dist = mean_right_dist / len(indright)\n",
    "        return mean_left_dist * len(left) / (len(left) + len(right)) + mean_right_dist * len(right) / (len(left) + len(right))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select the best split point for a dataset\n",
    "def get_split(df):\n",
    "    class_values = df[\"Survived\"]\n",
    "    b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "    for feature in df.columns:\n",
    "        if feature == 'Survived':\n",
    "            pass\n",
    "        else:\n",
    "            for index, row in df.iterrows():\n",
    "                left, right, indleft, indright = test_split(feature, row[feature], df)\n",
    "                dist = distance_index(left, right, indleft, indright)\n",
    "                groups = left, right, indleft, indright\n",
    "                if dist < b_score:\n",
    "                    b_index, b_value, b_score, b_groups = feature, row[feature], dist, groups\n",
    "    return {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
    "\n",
    "\n",
    "# Create a terminal node value (group means left or right)\n",
    "def to_terminal(group):\n",
    "    outcomes = [row[-1] for row in group]\n",
    "    return max(set(outcomes), key=outcomes.count)\n",
    " \n",
    "# Create child splits for a node or make terminal\n",
    "def split(node, max_depth, min_size, depth):\n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "    # check for a no split\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = to_terminal(left + right)\n",
    "        return\n",
    "    # check for max depth\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    # process left child\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left)\n",
    "        split(node['left'], max_depth, min_size, depth+1)\n",
    "    # process right child\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_split(right)\n",
    "        split(node['right'], max_depth, min_size, depth+1)\n",
    "        \n",
    "def build_tree(train, max_depth, min_size):\n",
    "    root = get_split(train)\n",
    "    split(root, max_depth, min_size, 1)\n",
    "    return root\n",
    "\n",
    "def print_tree(node, depth=0):\n",
    "    if isinstance(node, dict):\n",
    "        print('%s[%s < %.3f]' % ((depth*' ', (node['index']), node['value'])))\n",
    "        print_tree(node['left'], depth+1)\n",
    "        print_tree(node['right'], depth+1)\n",
    "    else:\n",
    "        print('%s[%s]' % ((depth*' ', node)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = [[2.771244718,1.784783929,0],\n",
    "    [1.728571309,1.169761413,0],\n",
    "    [3.678319846,2.81281357,0],\n",
    "    [3.961043357,2.61995032,0],\n",
    "    [2.999208922,2.209014212,0],\n",
    "    [7.497545867,3.162953546,1],\n",
    "    [9.00220326,3.339047188,1],\n",
    "    [7.444542326,0.476683375,1],\n",
    "    [10.12493903,3.234550982,1],\n",
    "    [6.642287351,3.319983761,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset, columns = ['X1', 'X2', 'class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_test_no_clust.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data_test_no_clust = full_data_test_no_clust.head(25)\n",
    "small_data_test_no_clust[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = build_tree(small_data_test_no_clust, 2, 1)\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def test_split(index, value, dataset):\n",
    "    left, right = list(), list()\n",
    "    for row in dataset:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right\n",
    " \n",
    "# Calculate the Gini index for a split dataset\n",
    "def gini_index(groups, classes):\n",
    "    # count all samples at split point\n",
    "    n_instances = float(sum([len(group) for group in groups]))\n",
    "    # sum weighted Gini index for each group\n",
    "    gini = 0.0\n",
    "    for group in groups:\n",
    "        size = float(len(group))\n",
    "        # avoid divide by zero\n",
    "        if size == 0:\n",
    "            continue\n",
    "        score = 0.0\n",
    "        # score the group based on the score for each class\n",
    "        for class_val in classes:\n",
    "            p = [row[-1] for row in group].count(class_val) / size\n",
    "            score += p * p\n",
    "        # weight the group score by its relative size\n",
    "        gini += (1.0 - score) * (size / n_instances)\n",
    "    return gini\n",
    " \n",
    "# Select the best split point for a dataset\n",
    "def get_split(dataset):\n",
    "    class_values = list(set(row[-1] for row in dataset))\n",
    "    b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "    for index in range(len(dataset[0])-1):\n",
    "        for row in dataset:\n",
    "            groups = test_split(index, row[index], dataset)\n",
    "            gini = gini_index(groups, class_values)\n",
    "            if gini < b_score:\n",
    "                b_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    "    return {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
    " \n",
    "# Create a terminal node value\n",
    "def to_terminal(group):\n",
    "    outcomes = [row[-1] for row in group]\n",
    "    return max(set(outcomes), key=outcomes.count)\n",
    " \n",
    "# Create child splits for a node or make terminal\n",
    "def split(node, max_depth, min_size, depth):\n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "    # check for a no split\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = to_terminal(left + right)\n",
    "        return\n",
    "    # check for max depth\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    # process left child\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left)\n",
    "        split(node['left'], max_depth, min_size, depth+1)\n",
    "    # process right child\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_split(right)\n",
    "        split(node['right'], max_depth, min_size, depth+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build a decision tree\n",
    "def build_tree(train, max_depth, min_size):\n",
    "    root = get_split(train)\n",
    "    split(root, max_depth, min_size, 1)\n",
    "    return root\n",
    " \n",
    "# Print a decision tree\n",
    "def print_tree(node, depth=0):\n",
    "    if isinstance(node, dict):\n",
    "        print(type(node['index']+1))\n",
    "        print(type(node['value']))\n",
    "        print('%s[X%d < %.3f]' % ((depth*' ', (node['index']+1), node['value'])))\n",
    "        print_tree(node['left'], depth+1)\n",
    "        print_tree(node['right'], depth+1)\n",
    "    else:\n",
    "        print('%s[%s]' % ((depth*' ', node)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = build_tree(dataset, 3, 1)\n",
    "print_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(x):\n",
    "    if x == 3: \n",
    "        continue\n",
    "    if x % 3 == 0:\n",
    "        print(\"hi\")\n",
    "    else:\n",
    "        print('no')\n",
    "foo(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
